# å›¾ä¹¦APPç”¨æˆ·æ¨¡å— - ç”¨æˆ·ä½“éªŒä¼˜åŒ–æ–‡æ¡£

## æ–‡æ¡£ä¿¡æ¯
- **æ–‡æ¡£ç‰ˆæœ¬**: 1.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-10-14
- **æ€è€ƒæ¨¡å¼**: UltraThinkæ·±åº¦åˆ†æ
- **å…³æ³¨é‡ç‚¹**: è·¨è®¾å¤‡ä½“éªŒã€ç¦»çº¿åŠŸèƒ½ã€ç¤¾äº¤äº’åŠ¨

---

## 1. è·¨è®¾å¤‡åŒæ­¥ä½“éªŒä¼˜åŒ–

### 1.1 å½“å‰ç—›ç‚¹åˆ†æ

**ç”¨æˆ·åœºæ™¯ï¼š**
```
æ—©ä¸Šï¼šæ‰‹æœºä¸Šé˜…è¯»åˆ°ç¬¬50é¡µ
ä¸­åˆï¼šiPadç»§ç»­é˜…è¯»ï¼Œä½†è¿›åº¦æ²¡æœ‰åŒæ­¥ï¼Œéœ€è¦æ‰‹åŠ¨ç¿»åˆ°ç¬¬50é¡µ
æ™šä¸Šï¼šKindleä¸Šé˜…è¯»ï¼Œç¬”è®°å’Œåˆ’çº¿éƒ½ä¸è§äº†
```

**é—®é¢˜æ ¹æºï¼š**
1. âŒ ç¼ºå°‘å®æ—¶åŒæ­¥æœºåˆ¶
2. âŒ å†²çªè§£å†³ç­–ç•¥ä¸æ˜ç¡®
3. âŒ ç¦»çº¿ä¿®æ”¹æ— æ³•åˆå¹¶
4. âŒ ä¸åŒè®¾å¤‡ç±»å‹çš„åŒæ­¥ä¼˜å…ˆçº§æœªå®šä¹‰

---

### 1.2 è·¨è®¾å¤‡åŒæ­¥æ¶æ„è®¾è®¡

#### å®Œæ•´åŒæ­¥è¡¨è®¾è®¡

```sql
CREATE TABLE user_sync_records (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    device_id VARCHAR(100) NOT NULL,

    -- åŒæ­¥å¯¹è±¡
    sync_type ENUM('progress', 'bookmark', 'note', 'preference', 'book_list') NOT NULL,
    resource_type VARCHAR(50) COMMENT 'èµ„æºç±»å‹ï¼ˆbook/audiobookï¼‰',
    resource_id BIGINT COMMENT 'èµ„æºID',

    -- åŒæ­¥æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
    sync_data JSON NOT NULL,

    -- åŒæ­¥çŠ¶æ€
    sync_status ENUM('pending', 'synced', 'conflict', 'resolved') DEFAULT 'pending',
    conflict_device_id VARCHAR(100) COMMENT 'å†²çªæ¥æºè®¾å¤‡ID',
    conflict_resolution VARCHAR(50) COMMENT 'å†²çªè§£å†³ç­–ç•¥',

    -- æ—¶é—´æˆ³ï¼ˆç”¨äºè§£å†³å†²çªï¼‰
    client_timestamp BIGINT NOT NULL COMMENT 'å®¢æˆ·ç«¯æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰',
    server_timestamp BIGINT NOT NULL COMMENT 'æœåŠ¡å™¨æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰',
    synced_at DATETIME COMMENT 'åŒæ­¥å®Œæˆæ—¶é—´',

    -- ç‰ˆæœ¬æ§åˆ¶
    version INT DEFAULT 1 COMMENT 'æ•°æ®ç‰ˆæœ¬å·',
    previous_version INT COMMENT 'å‰ä¸€ä¸ªç‰ˆæœ¬å·',

    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_user_device (user_id, device_id),
    INDEX idx_sync_status (sync_status),
    INDEX idx_resource (resource_type, resource_id),
    INDEX idx_sync_type (sync_type)
) COMMENT='è·¨è®¾å¤‡åŒæ­¥è®°å½•è¡¨';

-- åŒæ­¥å†²çªè¡¨ï¼ˆè®°å½•å†²çªè¯¦æƒ…ï¼‰
CREATE TABLE user_sync_conflicts (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,

    -- å†²çªä¿¡æ¯
    conflict_type VARCHAR(50) NOT NULL,
    conflict_description TEXT,

    -- å†²çªåŒæ–¹
    device_a_id VARCHAR(100) NOT NULL,
    device_a_data JSON NOT NULL,
    device_a_timestamp BIGINT NOT NULL,

    device_b_id VARCHAR(100) NOT NULL,
    device_b_data JSON NOT NULL,
    device_b_timestamp BIGINT NOT NULL,

    -- è§£å†³æ–¹æ¡ˆ
    resolution_strategy VARCHAR(50) COMMENT 'latest_wins/merge/manual',
    resolved_data JSON COMMENT 'è§£å†³åçš„æ•°æ®',
    resolved_by VARCHAR(50) COMMENT 'è§£å†³æ–¹å¼ï¼ˆauto/userï¼‰',
    resolved_at DATETIME,

    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_user_id (user_id),
    INDEX idx_resolved (resolved_at)
) COMMENT='åŒæ­¥å†²çªè®°å½•è¡¨';
```

---

### 1.3 å®æ—¶åŒæ­¥å®ç°

#### WebSocketåŒæ­¥æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  iPhone     â”‚     â”‚   iPad      â”‚     â”‚   Android   â”‚
â”‚  (Device A) â”‚     â”‚  (Device B) â”‚     â”‚  (Device C) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â”‚ WebSocket         â”‚ WebSocket         â”‚ WebSocket
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Sync Gateway       â”‚
                â”‚  (WebSocket Server)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚               â”‚               â”‚
           â†“               â†“               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Redis   â”‚   â”‚   MySQL   â”‚   â”‚   Kafka   â”‚
    â”‚ (å®æ—¶é˜Ÿåˆ—)â”‚   â”‚(æŒä¹…åŒ–)   â”‚   â”‚(æ¶ˆæ¯é˜Ÿåˆ—) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### åŒæ­¥æœåŠ¡å®ç°

```python
import asyncio
import websockets
import json
from datetime import datetime

class SyncService:
    """è·¨è®¾å¤‡åŒæ­¥æœåŠ¡"""

    def __init__(self):
        self.active_connections = {}  # {user_id: {device_id: websocket}}
        self.redis = RedisClient()
        self.mysql = MySQLClient()

    async def handle_client(self, websocket, user_id: int, device_id: str):
        """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
        # 1. æ³¨å†Œè¿æ¥
        if user_id not in self.active_connections:
            self.active_connections[user_id] = {}

        self.active_connections[user_id][device_id] = websocket

        try:
            # 2. å‘é€åˆå§‹åŒæ­¥æ•°æ®
            await self.send_initial_sync(websocket, user_id, device_id)

            # 3. æŒç»­ç›‘å¬æ¶ˆæ¯
            async for message in websocket:
                await self.handle_sync_message(
                    user_id, device_id, json.loads(message)
                )

        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            # 4. ç§»é™¤è¿æ¥
            if user_id in self.active_connections:
                self.active_connections[user_id].pop(device_id, None)

    async def send_initial_sync(self, websocket, user_id: int,
                               device_id: str):
        """å‘é€åˆå§‹åŒæ­¥æ•°æ®ï¼ˆå®¢æˆ·ç«¯è¿æ¥æ—¶ï¼‰"""
        # è·å–è¯¥è®¾å¤‡æœ€ååŒæ­¥æ—¶é—´
        last_sync = await self.mysql.fetchone("""
            SELECT MAX(server_timestamp) as last_sync_time
            FROM user_sync_records
            WHERE user_id = %s AND device_id = %s
        """, (user_id, device_id))

        last_sync_time = last_sync['last_sync_time'] if last_sync else 0

        # è·å–ä¹‹åçš„æ‰€æœ‰æ›´æ–°
        pending_syncs = await self.mysql.fetchall("""
            SELECT * FROM user_sync_records
            WHERE user_id = %s
            AND device_id != %s
            AND server_timestamp > %s
            ORDER BY server_timestamp ASC
        """, (user_id, device_id, last_sync_time))

        # å‘é€ç»™å®¢æˆ·ç«¯
        for sync in pending_syncs:
            await websocket.send(json.dumps({
                'type': 'sync_update',
                'sync_type': sync['sync_type'],
                'resource_id': sync['resource_id'],
                'data': sync['sync_data'],
                'timestamp': sync['server_timestamp']
            }))

    async def handle_sync_message(self, user_id: int, device_id: str,
                                  message: dict):
        """å¤„ç†åŒæ­¥æ¶ˆæ¯"""
        sync_type = message['type']

        if sync_type == 'update_progress':
            await self.sync_reading_progress(user_id, device_id, message)
        elif sync_type == 'add_bookmark':
            await self.sync_bookmark(user_id, device_id, message)
        elif sync_type == 'add_note':
            await self.sync_note(user_id, device_id, message)
        elif sync_type == 'update_preference':
            await self.sync_preference(user_id, device_id, message)

    async def sync_reading_progress(self, user_id: int, device_id: str,
                                    message: dict):
        """åŒæ­¥é˜…è¯»è¿›åº¦"""
        book_id = message['book_id']
        current_page = message['current_page']
        progress = message['progress']
        client_timestamp = message['timestamp']

        server_timestamp = int(datetime.now().timestamp() * 1000)

        # 1. æ£€æŸ¥å†²çª
        existing_sync = await self.redis.get(
            f'sync:progress:{user_id}:{book_id}'
        )

        if existing_sync:
            existing_data = json.loads(existing_sync)

            # æ—¶é—´æˆ³å†²çªæ£€æµ‹ï¼ˆ5ç§’å†…çš„æ›´æ–°è§†ä¸ºå†²çªï¼‰
            time_diff = abs(client_timestamp - existing_data['timestamp'])

            if time_diff < 5000:  # 5ç§’
                # å†²çªï¼šè®°å½•å†²çªä¿¡æ¯
                await self.record_conflict(
                    user_id, book_id, existing_data, message
                )

                # ä½¿ç”¨æœ€æ–°æ—¶é—´æˆ³çš„æ•°æ®
                if client_timestamp > existing_data['timestamp']:
                    winning_data = message
                else:
                    winning_data = existing_data

                await self.resolve_and_broadcast(
                    user_id, book_id, winning_data, 'latest_wins'
                )
                return

        # 2. æ— å†²çªï¼šç›´æ¥æ›´æ–°
        sync_data = {
            'book_id': book_id,
            'current_page': current_page,
            'progress': progress,
            'timestamp': server_timestamp,
            'device_id': device_id
        }

        # 2.1 æ›´æ–°Redisç¼“å­˜
        await self.redis.setex(
            f'sync:progress:{user_id}:{book_id}',
            3600,
            json.dumps(sync_data)
        )

        # 2.2 å†™å…¥åŒæ­¥è®°å½•è¡¨
        await self.mysql.execute("""
            INSERT INTO user_sync_records
            (user_id, device_id, sync_type, resource_type, resource_id,
             sync_data, sync_status, client_timestamp, server_timestamp,
             version, created_at)
            VALUES (%s, %s, 'progress', 'book', %s, %s, 'synced', %s, %s, 1, NOW())
        """, (
            user_id, device_id, book_id,
            json.dumps(sync_data),
            client_timestamp, server_timestamp
        ))

        # 2.3 æ›´æ–°å®é™…çš„é˜…è¯»è¿›åº¦è¡¨
        await self.mysql.execute("""
            UPDATE user_reading_records
            SET current_page = %s,
                reading_progress = %s,
                last_reading_at = NOW()
            WHERE user_id = %s AND book_id = %s
        """, (current_page, progress, user_id, book_id))

        # 3. å¹¿æ’­åˆ°å…¶ä»–è®¾å¤‡
        await self.broadcast_to_other_devices(
            user_id, device_id, {
                'type': 'sync_update',
                'sync_type': 'progress',
                'book_id': book_id,
                'data': sync_data
            }
        )

    async def broadcast_to_other_devices(self, user_id: int,
                                        source_device_id: str,
                                        message: dict):
        """å¹¿æ’­æ¶ˆæ¯åˆ°ç”¨æˆ·çš„å…¶ä»–è®¾å¤‡"""
        if user_id not in self.active_connections:
            return

        tasks = []
        for device_id, websocket in self.active_connections[user_id].items():
            if device_id != source_device_id:
                tasks.append(websocket.send(json.dumps(message)))

        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

    async def record_conflict(self, user_id: int, book_id: int,
                             data_a: dict, data_b: dict):
        """è®°å½•åŒæ­¥å†²çª"""
        await self.mysql.execute("""
            INSERT INTO user_sync_conflicts
            (user_id, conflict_type, conflict_description,
             device_a_id, device_a_data, device_a_timestamp,
             device_b_id, device_b_data, device_b_timestamp,
             created_at)
            VALUES (%s, 'progress', %s, %s, %s, %s, %s, %s, %s, NOW())
        """, (
            user_id,
            f'Reading progress conflict for book {book_id}',
            data_a['device_id'], json.dumps(data_a), data_a['timestamp'],
            data_b['device_id'], json.dumps(data_b), data_b['timestamp']
        ))
```

---

### 1.4 å†²çªè§£å†³ç­–ç•¥

#### ç­–ç•¥1ï¼šLast-Write-Winsï¼ˆæœ€æ–°å†™å…¥ä¼˜å…ˆï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- é˜…è¯»è¿›åº¦
- ç”¨æˆ·åå¥½è®¾ç½®
- æœ€åé˜…è¯»ä½ç½®

**å®ç°é€»è¾‘ï¼š**
```python
def resolve_conflict_latest_wins(conflict: dict) -> dict:
    """æœ€æ–°æ—¶é—´æˆ³çš„æ•°æ®è·èƒœ"""
    if conflict['device_a_timestamp'] > conflict['device_b_timestamp']:
        return conflict['device_a_data']
    else:
        return conflict['device_b_data']
```

#### ç­–ç•¥2ï¼šMergeï¼ˆåˆå¹¶ï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- ä¹¦ç­¾åˆ—è¡¨
- ç¬”è®°åˆ—è¡¨
- ä¹¦å•å†…å®¹

**å®ç°é€»è¾‘ï¼š**
```python
def resolve_conflict_merge(conflict: dict, sync_type: str) -> dict:
    """åˆå¹¶ä¸¤è¾¹çš„æ•°æ®"""
    data_a = conflict['device_a_data']
    data_b = conflict['device_b_data']

    if sync_type == 'bookmark':
        # åˆå¹¶ä¹¦ç­¾ï¼ˆå»é‡ï¼‰
        bookmarks_a = set(json.dumps(b) for b in data_a.get('bookmarks', []))
        bookmarks_b = set(json.dumps(b) for b in data_b.get('bookmarks', []))

        merged_bookmarks = [
            json.loads(b) for b in bookmarks_a.union(bookmarks_b)
        ]

        return {'bookmarks': merged_bookmarks}

    elif sync_type == 'note':
        # åˆå¹¶ç¬”è®°ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
        notes_a = data_a.get('notes', [])
        notes_b = data_b.get('notes', [])

        merged_notes = notes_a + notes_b
        merged_notes.sort(key=lambda x: x['created_at'])

        # å»é‡ï¼ˆæ ¹æ®note_idï¼‰
        seen = set()
        unique_notes = []
        for note in merged_notes:
            if note['note_id'] not in seen:
                seen.add(note['note_id'])
                unique_notes.append(note)

        return {'notes': unique_notes}

    return {}
```

#### ç­–ç•¥3ï¼šManualï¼ˆæ‰‹åŠ¨è§£å†³ï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- é‡è¦çš„å†…å®¹ä¿®æ”¹
- æ— æ³•è‡ªåŠ¨åˆå¹¶çš„å†²çª

**å®ç°é€»è¾‘ï¼š**
```python
async def prompt_user_resolve_conflict(user_id: int, conflict_id: int):
    """æç¤ºç”¨æˆ·æ‰‹åŠ¨è§£å†³å†²çª"""
    conflict = await mysql.fetchone("""
        SELECT * FROM user_sync_conflicts WHERE id = %s
    """, (conflict_id,))

    # 1. æ¨é€é€šçŸ¥ç»™ç”¨æˆ·
    await notification_service.send_push(
        user_id,
        title="åŒæ­¥å†²çªéœ€è¦æ‚¨çš„å¤„ç†",
        body=f"æ‚¨çš„è®¾å¤‡åœ¨{conflict['conflict_type']}æ—¶å‡ºç°å†²çª",
        data={
            'conflict_id': conflict_id,
            'action': 'resolve_conflict'
        }
    )

    # 2. ç”¨æˆ·åœ¨APPä¸­é€‰æ‹©
    #    - ä½¿ç”¨è®¾å¤‡Açš„æ•°æ®
    #    - ä½¿ç”¨è®¾å¤‡Bçš„æ•°æ®
    #    - æ‰‹åŠ¨åˆå¹¶

    # 3. ç­‰å¾…ç”¨æˆ·æ“ä½œï¼ˆè¶…æ—¶è‡ªåŠ¨ä½¿ç”¨latest_winsç­–ç•¥ï¼‰
    timeout = 300  # 5åˆ†é’Ÿ
    # ...
```

---

## 2. ç¦»çº¿é˜…è¯»ä½“éªŒä¼˜åŒ–

### 2.1 ç¦»çº¿å†…å®¹ç®¡ç†

#### ç¦»çº¿å›¾ä¹¦è¡¨è®¾è®¡

```sql
CREATE TABLE user_offline_books (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    book_id BIGINT NOT NULL,
    device_id VARCHAR(100) NOT NULL,

    -- ä¸‹è½½çŠ¶æ€
    download_status ENUM('queued', 'downloading', 'completed', 'failed', 'paused') DEFAULT 'queued',
    download_progress DECIMAL(5, 2) DEFAULT 0.00,

    -- æ–‡ä»¶ä¿¡æ¯
    downloaded_size_bytes BIGINT DEFAULT 0 COMMENT 'å·²ä¸‹è½½å­—èŠ‚æ•°',
    total_size_bytes BIGINT COMMENT 'æ€»å­—èŠ‚æ•°',
    file_format VARCHAR(20) COMMENT 'epub/pdf/mobi',
    quality VARCHAR(20) COMMENT 'standard/high/ultra',

    -- å­˜å‚¨ä¿¡æ¯
    local_storage_path VARCHAR(255) COMMENT 'æœ¬åœ°å­˜å‚¨è·¯å¾„',
    file_hash VARCHAR(64) COMMENT 'SHA-256æ–‡ä»¶å“ˆå¸Œï¼ˆæ ¡éªŒå®Œæ•´æ€§ï¼‰',

    -- æœ‰æ•ˆæœŸï¼ˆVIPç”¨æˆ·å¯èƒ½æ›´é•¿ï¼‰
    expires_at DATETIME COMMENT 'ç¦»çº¿å†…å®¹è¿‡æœŸæ—¶é—´',
    last_accessed_at DATETIME COMMENT 'æœ€åè®¿é—®æ—¶é—´',

    -- ä¸‹è½½ä»»åŠ¡ä¿¡æ¯
    download_started_at DATETIME COMMENT 'å¼€å§‹ä¸‹è½½æ—¶é—´',
    download_completed_at DATETIME COMMENT 'ä¸‹è½½å®Œæˆæ—¶é—´',
    retry_count INT DEFAULT 0 COMMENT 'é‡è¯•æ¬¡æ•°',
    error_message TEXT COMMENT 'é”™è¯¯ä¿¡æ¯',

    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    UNIQUE KEY uk_user_book_device (user_id, book_id, device_id),
    INDEX idx_download_status (download_status),
    INDEX idx_expires_at (expires_at),
    INDEX idx_user_device (user_id, device_id)
) COMMENT='ç”¨æˆ·ç¦»çº¿å›¾ä¹¦è¡¨';

-- ç¦»çº¿å†…å®¹ç« èŠ‚è¡¨ï¼ˆæ”¯æŒæŒ‰ç« èŠ‚ä¸‹è½½ï¼‰
CREATE TABLE user_offline_chapters (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    offline_book_id BIGINT NOT NULL,
    chapter_id BIGINT NOT NULL,

    download_status ENUM('pending', 'completed', 'failed') DEFAULT 'pending',
    local_path VARCHAR(255),
    file_size_bytes BIGINT,

    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY (offline_book_id) REFERENCES user_offline_books(id) ON DELETE CASCADE,
    INDEX idx_offline_book (offline_book_id)
) COMMENT='ç¦»çº¿ç« èŠ‚è¡¨';
```

---

### 2.2 æ™ºèƒ½é¢„ä¸‹è½½æœºåˆ¶

#### é¢„æµ‹ç”¨æˆ·é˜…è¯»æ„å›¾

```python
class SmartPredownloader:
    """æ™ºèƒ½é¢„ä¸‹è½½æœåŠ¡"""

    async def predict_next_books(self, user_id: int) -> list:
        """é¢„æµ‹ç”¨æˆ·æ¥ä¸‹æ¥å¯èƒ½é˜…è¯»çš„ä¹¦ç±"""
        # 1. è·å–ç”¨æˆ·çš„"æƒ³è¯»"åˆ—è¡¨
        want_to_read = await mysql.fetchall("""
            SELECT book_id FROM user_reading_records
            WHERE user_id = %s
            AND reading_status = 'want_to_read'
            ORDER BY created_at DESC
            LIMIT 5
        """, (user_id,))

        # 2. è·å–ç”¨æˆ·æ­£åœ¨é˜…è¯»ä½†æœªå®Œæˆçš„ä¹¦
        reading_now = await mysql.fetchall("""
            SELECT book_id FROM user_reading_records
            WHERE user_id = %s
            AND reading_status = 'reading'
            AND reading_progress < 95
            ORDER BY last_reading_at DESC
            LIMIT 3
        """, (user_id,))

        # 3. ååŒè¿‡æ»¤æ¨èï¼ˆç›¸ä¼¼ç”¨æˆ·å–œæ¬¢çš„ä¹¦ï¼‰
        recommended = await self.collaborative_filtering(user_id, limit=3)

        # 4. åŒä¸€ä½œè€…/ç³»åˆ—çš„å…¶ä»–ä¹¦
        related_books = await self.get_related_books(user_id, limit=2)

        # 5. åˆå¹¶å¹¶å»é‡
        predicted_books = []
        seen = set()

        for book_list in [want_to_read, reading_now, recommended, related_books]:
            for book in book_list:
                book_id = book['book_id']
                if book_id not in seen:
                    seen.add(book_id)
                    predicted_books.append(book_id)

        return predicted_books[:10]  # æœ€å¤šé¢„æµ‹10æœ¬

    async def auto_predownload(self, user_id: int, device_id: str):
        """è‡ªåŠ¨é¢„ä¸‹è½½ï¼ˆWiFiç¯å¢ƒ + å……ç”µæ—¶ï¼‰"""
        # 1. æ£€æŸ¥è®¾å¤‡çŠ¶æ€
        device_status = await self.get_device_status(user_id, device_id)

        if not device_status['is_wifi'] or not device_status['is_charging']:
            return  # ä»…åœ¨WiFi+å……ç”µæ—¶é¢„ä¸‹è½½

        # 2. æ£€æŸ¥å­˜å‚¨ç©ºé—´
        available_space_mb = device_status['available_storage_mb']

        if available_space_mb < 500:  # è‡³å°‘ä¿ç•™500MBç©ºé—´
            return

        # 3. è·å–é¢„æµ‹çš„ä¹¦ç±
        predicted_books = await self.predict_next_books(user_id)

        # 4. æ£€æŸ¥å“ªäº›ä¹¦å·²ç»ä¸‹è½½
        already_downloaded = await mysql.fetchall("""
            SELECT book_id FROM user_offline_books
            WHERE user_id = %s
            AND device_id = %s
            AND download_status = 'completed'
        """, (user_id, device_id))

        downloaded_ids = {book['book_id'] for book in already_downloaded}

        # 5. ä¸‹è½½æœªä¸‹è½½çš„ä¹¦ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        to_download = [
            book_id for book_id in predicted_books
            if book_id not in downloaded_ids
        ]

        for book_id in to_download[:3]:  # æœ€å¤šé¢„ä¸‹è½½3æœ¬
            await self.start_download(user_id, book_id, device_id, priority='low')

    async def start_download(self, user_id: int, book_id: int,
                            device_id: str, priority: str = 'normal'):
        """å¼€å§‹ä¸‹è½½å›¾ä¹¦"""
        # 1. åˆ›å»ºä¸‹è½½ä»»åŠ¡
        await mysql.execute("""
            INSERT INTO user_offline_books
            (user_id, book_id, device_id, download_status,
             download_started_at, created_at)
            VALUES (%s, %s, %s, 'queued', NOW(), NOW())
        """, (user_id, book_id, device_id))

        # 2. åŠ å…¥ä¸‹è½½é˜Ÿåˆ—ï¼ˆRedisï¼‰
        queue_key = f'download_queue:{priority}'  # low/normal/high
        await redis.lpush(queue_key, json.dumps({
            'user_id': user_id,
            'book_id': book_id,
            'device_id': device_id
        }))

        # 3. è§¦å‘ä¸‹è½½ä»»åŠ¡
        await download_worker.process_queue()
```

---

### 2.3 æ–­ç‚¹ç»­ä¼ å®ç°

```python
import aiofiles
import aiohttp

class ResumeableDownloader:
    """æ”¯æŒæ–­ç‚¹ç»­ä¼ çš„ä¸‹è½½å™¨"""

    async def download_book(self, user_id: int, book_id: int,
                           device_id: str):
        """ä¸‹è½½å›¾ä¹¦ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        # 1. è·å–ä¸‹è½½ä»»åŠ¡
        task = await mysql.fetchone("""
            SELECT * FROM user_offline_books
            WHERE user_id = %s AND book_id = %s AND device_id = %s
        """, (user_id, book_id, device_id))

        if not task:
            raise ValueError("Download task not found")

        # 2. è·å–å›¾ä¹¦ä¸‹è½½URL
        book_info = await self.get_book_download_info(book_id)
        download_url = book_info['url']
        total_size = book_info['size_bytes']
        local_path = self.get_local_path(user_id, book_id)

        # 3. æ£€æŸ¥å·²ä¸‹è½½çš„å¤§å°ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
        downloaded_size = task['downloaded_size_bytes'] or 0

        if downloaded_size > 0 and os.path.exists(local_path):
            # æ–­ç‚¹ç»­ä¼ ï¼šä»å·²ä¸‹è½½ä½ç½®ç»§ç»­
            resume_from = downloaded_size
            mode = 'ab'  # append binary
        else:
            # å…¨æ–°ä¸‹è½½
            resume_from = 0
            mode = 'wb'  # write binary

        # 4. å‘èµ·HTTPè¯·æ±‚ï¼ˆå¸¦Rangeå¤´ï¼‰
        headers = {
            'Range': f'bytes={resume_from}-',
            'User-Agent': 'LibraryApp/1.0'
        }

        async with aiohttp.ClientSession() as session:
            async with session.get(download_url, headers=headers) as response:
                if response.status not in [200, 206]:  # 206 Partial Content
                    raise Exception(f"Download failed: {response.status}")

                # 5. å†™å…¥æ–‡ä»¶
                async with aiofiles.open(local_path, mode) as f:
                    chunk_size = 64 * 1024  # 64KB per chunk
                    downloaded = resume_from

                    async for chunk in response.content.iter_chunked(chunk_size):
                        await f.write(chunk)
                        downloaded += len(chunk)

                        # æ›´æ–°è¿›åº¦
                        progress = (downloaded / total_size) * 100
                        await self.update_progress(
                            user_id, book_id, device_id,
                            downloaded, progress
                        )

                        # æ¨é€è¿›åº¦é€šçŸ¥ï¼ˆæ¯5%ï¼‰
                        if int(progress) % 5 == 0:
                            await self.notify_progress(
                                user_id, device_id, book_id, progress
                            )

        # 6. ä¸‹è½½å®Œæˆï¼šæ ¡éªŒå“ˆå¸Œ
        file_hash = await self.calculate_file_hash(local_path)

        if file_hash != book_info['expected_hash']:
            # å“ˆå¸Œä¸åŒ¹é…ï¼Œæ–‡ä»¶æŸå
            await self.mark_download_failed(
                user_id, book_id, device_id, 'Hash mismatch'
            )
            return

        # 7. æ ‡è®°å®Œæˆ
        await mysql.execute("""
            UPDATE user_offline_books
            SET download_status = 'completed',
                downloaded_size_bytes = %s,
                local_storage_path = %s,
                file_hash = %s,
                download_completed_at = NOW()
            WHERE user_id = %s AND book_id = %s AND device_id = %s
        """, (
            downloaded, local_path, file_hash,
            user_id, book_id, device_id
        ))

    async def update_progress(self, user_id: int, book_id: int,
                             device_id: str, downloaded: int, progress: float):
        """æ›´æ–°ä¸‹è½½è¿›åº¦"""
        await mysql.execute("""
            UPDATE user_offline_books
            SET downloaded_size_bytes = %s,
                download_progress = %s,
                updated_at = NOW()
            WHERE user_id = %s AND book_id = %s AND device_id = %s
        """, (downloaded, progress, user_id, book_id, device_id))

        # åŒæ—¶æ›´æ–°Redisï¼ˆå®æ—¶æŸ¥è¯¢ï¼‰
        await redis.setex(
            f'download:progress:{user_id}:{book_id}',
            3600,
            json.dumps({'progress': progress, 'downloaded': downloaded})
        )

    async def calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶SHA-256å“ˆå¸Œ"""
        import hashlib

        sha256 = hashlib.sha256()
        async with aiofiles.open(file_path, 'rb') as f:
            while chunk := await f.read(8192):
                sha256.update(chunk)

        return sha256.hexdigest()
```

---

### 2.4 ç¦»çº¿å†…å®¹è¿‡æœŸæ¸…ç†

```python
class OfflineContentCleaner:
    """ç¦»çº¿å†…å®¹æ¸…ç†æœåŠ¡"""

    async def clean_expired_books(self):
        """å®šæ—¶ä»»åŠ¡ï¼šæ¸…ç†è¿‡æœŸçš„ç¦»çº¿å›¾ä¹¦"""
        # 1. æŸ¥æ‰¾è¿‡æœŸçš„ç¦»çº¿å›¾ä¹¦
        expired_books = await mysql.fetchall("""
            SELECT * FROM user_offline_books
            WHERE expires_at < NOW()
            AND download_status = 'completed'
        """)

        for book in expired_books:
            # 2. åˆ é™¤æœ¬åœ°æ–‡ä»¶
            if book['local_storage_path'] and os.path.exists(book['local_storage_path']):
                os.remove(book['local_storage_path'])

            # 3. æ›´æ–°æ•°æ®åº“è®°å½•
            await mysql.execute("""
                UPDATE user_offline_books
                SET download_status = 'expired',
                    local_storage_path = NULL
                WHERE id = %s
            """, (book['id'],))

            # 4. æ¨é€é€šçŸ¥ç»™ç”¨æˆ·
            await notification_service.send_push(
                book['user_id'],
                title="ç¦»çº¿å†…å®¹å·²è¿‡æœŸ",
                body=f"ã€Š{book['book_name']}ã€‹çš„ç¦»çº¿å†…å®¹å·²è¿‡æœŸï¼Œè¯·é‡æ–°ä¸‹è½½"
            )

    async def auto_cleanup_lru(self, user_id: int, device_id: str,
                              target_free_space_mb: int = 500):
        """è‡ªåŠ¨æ¸…ç†æœ€å°‘ä½¿ç”¨çš„ç¦»çº¿å›¾ä¹¦ï¼ˆLRUç­–ç•¥ï¼‰"""
        # 1. è·å–è®¾å¤‡å­˜å‚¨ç©ºé—´
        current_free_space = await self.get_device_free_space(user_id, device_id)

        if current_free_space >= target_free_space_mb:
            return  # ç©ºé—´å……è¶³ï¼Œæ— éœ€æ¸…ç†

        # 2. æŒ‰æœ€åè®¿é—®æ—¶é—´æ’åºï¼ˆæœ€ä¹…æœªç”¨çš„ä¼˜å…ˆæ¸…ç†ï¼‰
        offline_books = await mysql.fetchall("""
            SELECT * FROM user_offline_books
            WHERE user_id = %s AND device_id = %s
            AND download_status = 'completed'
            ORDER BY last_accessed_at ASC
        """, (user_id, device_id))

        # 3. é€ä¸ªåˆ é™¤ç›´åˆ°ç©ºé—´è¶³å¤Ÿ
        freed_space = 0
        for book in offline_books:
            if current_free_space + freed_space >= target_free_space_mb:
                break

            # åˆ é™¤æ–‡ä»¶
            file_size_mb = book['total_size_bytes'] / (1024 * 1024)
            if os.path.exists(book['local_storage_path']):
                os.remove(book['local_storage_path'])
                freed_space += file_size_mb

            # æ›´æ–°æ•°æ®åº“
            await mysql.execute("""
                UPDATE user_offline_books
                SET download_status = 'deleted',
                    local_storage_path = NULL
                WHERE id = %s
            """, (book['id'],))

        logger.info(f"LRU cleanup freed {freed_space:.2f}MB for user {user_id}")
```

---

## 3. ç¤¾äº¤äº’åŠ¨åŠŸèƒ½å¢å¼º

### 3.1 ç¬”è®°çš„ç¤¾äº¤åŒ–

#### å…¬å¼€ç¬”è®°å±•ç¤º

```sql
-- ç¬”è®°ç‚¹èµè¡¨
CREATE TABLE user_note_likes (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    note_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,

    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

    UNIQUE KEY uk_note_user (note_id, user_id),
    INDEX idx_note_id (note_id),
    INDEX idx_user_id (user_id),

    FOREIGN KEY (note_id) REFERENCES user_reading_notes(id) ON DELETE CASCADE,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
) COMMENT='ç¬”è®°ç‚¹èµè¡¨';

-- ç¬”è®°è¯„è®ºè¡¨
CREATE TABLE user_note_comments (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    note_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,

    comment_content TEXT NOT NULL,
    parent_comment_id BIGINT COMMENT 'çˆ¶è¯„è®ºIDï¼ˆæ”¯æŒå›å¤ï¼‰',

    likes_count INT DEFAULT 0,
    replies_count INT DEFAULT 0,

    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    deleted_at DATETIME,

    INDEX idx_note_id (note_id),
    INDEX idx_user_id (user_id),
    INDEX idx_parent (parent_comment_id),

    FOREIGN KEY (note_id) REFERENCES user_reading_notes(id) ON DELETE CASCADE,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
) COMMENT='ç¬”è®°è¯„è®ºè¡¨';
```

#### ç¬”è®°ç¤¾åŒºFeedæµ

```python
class NoteFeedService:
    """ç¬”è®°ç¤¾åŒºFeedæµæœåŠ¡"""

    async def get_public_notes_feed(self, user_id: int,
                                    page: int = 1, page_size: int = 20):
        """è·å–å…¬å¼€ç¬”è®°çš„Feedæµ"""
        offset = (page - 1) * page_size

        # 1. è·å–ç”¨æˆ·å…³æ³¨çš„äºº
        following_users = await mysql.fetchall("""
            SELECT target_user_id FROM user_relationships
            WHERE user_id = %s AND relationship_type = 'follow'
        """, (user_id,))

        following_ids = [u['target_user_id'] for u in following_users]
        following_ids.append(user_id)  # åŒ…æ‹¬è‡ªå·±

        # 2. æŸ¥è¯¢è¿™äº›ç”¨æˆ·çš„å…¬å¼€ç¬”è®°
        notes = await mysql.fetchall("""
            SELECT
                n.*,
                u.username, u.nickname,
                p.avatar_url,
                b.book_name, b.book_cover,
                n.likes_count, n.comments_count
            FROM user_reading_notes n
            JOIN users u ON n.user_id = u.id
            LEFT JOIN user_profiles p ON u.id = p.user_id
            LEFT JOIN books b ON n.book_id = b.id
            WHERE n.user_id IN (%s)
            AND n.is_public = TRUE
            AND n.deleted_at IS NULL
            ORDER BY n.created_at DESC
            LIMIT %s OFFSET %s
        """, (','.join(map(str, following_ids)), page_size, offset))

        # 3. è§£å¯†ç¬”è®°å†…å®¹ï¼ˆå¦‚æœåŠ å¯†ï¼‰
        for note in notes:
            if note['note_content_encrypted']:
                dek = await encryption.get_user_key(note['user_id'])
                note['content'] = encryption.decrypt_note_content(
                    note['user_id'],
                    dek,
                    note['note_content_encrypted'],
                    note['encryption_iv']
                )
            else:
                note['content'] = note['note_content']

            # åˆ é™¤åŠ å¯†å­—æ®µï¼ˆä¸è¿”å›ç»™å‰ç«¯ï¼‰
            del note['note_content_encrypted']
            del note['encryption_iv']

        return notes

    async def like_note(self, user_id: int, note_id: int):
        """ç‚¹èµç¬”è®°"""
        # 1. æ’å…¥ç‚¹èµè®°å½•ï¼ˆå¹‚ç­‰ï¼‰
        try:
            await mysql.execute("""
                INSERT INTO user_note_likes (note_id, user_id, created_at)
                VALUES (%s, %s, NOW())
            """, (note_id, user_id))

            # 2. å¢åŠ ç¬”è®°çš„ç‚¹èµæ•°
            await mysql.execute("""
                UPDATE user_reading_notes
                SET likes_count = likes_count + 1
                WHERE id = %s
            """, (note_id,))

            # 3. æ¨é€é€šçŸ¥ç»™ç¬”è®°ä½œè€…
            note_author = await mysql.fetchone("""
                SELECT user_id FROM user_reading_notes WHERE id = %s
            """, (note_id,))

            if note_author['user_id'] != user_id:
                await notification_service.send_push(
                    note_author['user_id'],
                    title="æœ‰äººèµäº†ä½ çš„ç¬”è®°",
                    body=f"ä½ çš„ç¬”è®°è·å¾—äº†æ–°çš„èµ"
                )

        except IntegrityError:
            # å·²ç»ç‚¹èµè¿‡äº†ï¼Œå¿½ç•¥
            pass

    async def comment_on_note(self, user_id: int, note_id: int,
                             comment_content: str,
                             parent_comment_id: int = None):
        """è¯„è®ºç¬”è®°"""
        # 1. æ’å…¥è¯„è®º
        result = await mysql.execute("""
            INSERT INTO user_note_comments
            (note_id, user_id, comment_content, parent_comment_id, created_at)
            VALUES (%s, %s, %s, %s, NOW())
        """, (note_id, user_id, comment_content, parent_comment_id))

        comment_id = result.lastrowid

        # 2. å¢åŠ ç¬”è®°çš„è¯„è®ºæ•°
        await mysql.execute("""
            UPDATE user_reading_notes
            SET comments_count = comments_count + 1
            WHERE id = %s
        """, (note_id,))

        # 3. å¦‚æœæ˜¯å›å¤è¯„è®ºï¼Œå¢åŠ çˆ¶è¯„è®ºçš„å›å¤æ•°
        if parent_comment_id:
            await mysql.execute("""
                UPDATE user_note_comments
                SET replies_count = replies_count + 1
                WHERE id = %s
            """, (parent_comment_id,))

        # 4. æ¨é€é€šçŸ¥
        note_author = await mysql.fetchone("""
            SELECT user_id FROM user_reading_notes WHERE id = %s
        """, (note_id,))

        if note_author['user_id'] != user_id:
            await notification_service.send_push(
                note_author['user_id'],
                title="æœ‰äººè¯„è®ºäº†ä½ çš„ç¬”è®°",
                body=comment_content[:50] + ('...' if len(comment_content) > 50 else '')
            )

        return comment_id
```

---

### 3.2 ä¹¦å•å…³æ³¨ä¸åä½œ

```sql
-- ä¹¦å•å…³æ³¨è¡¨
CREATE TABLE user_book_list_followers (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    list_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,

    followed_at DATETIME DEFAULT CURRENT_TIMESTAMP,

    UNIQUE KEY uk_list_user (list_id, user_id),
    INDEX idx_list_id (list_id),
    INDEX idx_user_id (user_id),

    FOREIGN KEY (list_id) REFERENCES user_book_lists(id) ON DELETE CASCADE,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
) COMMENT='ä¹¦å•å…³æ³¨è¡¨';

-- ä¹¦å•åä½œè¡¨ï¼ˆå…è®¸å¤šäººå…±åŒç»´æŠ¤ä¸€ä¸ªä¹¦å•ï¼‰
CREATE TABLE user_book_list_collaborators (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    list_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,

    role ENUM('owner', 'editor', 'contributor') DEFAULT 'contributor',
    permissions JSON COMMENT 'æƒé™é…ç½®ï¼ˆå¯æ·»åŠ /åˆ é™¤/æ’åºç­‰ï¼‰',

    invited_by BIGINT COMMENT 'é‚€è¯·äººID',
    invited_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    accepted_at DATETIME COMMENT 'æ¥å—é‚€è¯·æ—¶é—´',

    UNIQUE KEY uk_list_user (list_id, user_id),
    INDEX idx_list_id (list_id),

    FOREIGN KEY (list_id) REFERENCES user_book_lists(id) ON DELETE CASCADE,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
) COMMENT='ä¹¦å•åä½œè€…è¡¨';
```

#### åä½œä¹¦å•å®ç°

```python
class CollaborativeBookListService:
    """åä½œä¹¦å•æœåŠ¡"""

    async def invite_collaborator(self, list_id: int, owner_id: int,
                                 invitee_user_id: int, role: str = 'contributor'):
        """é‚€è¯·åä½œè€…"""
        # 1. éªŒè¯æƒé™ï¼ˆåªæœ‰ownerå¯ä»¥é‚€è¯·ï¼‰
        list_info = await mysql.fetchone("""
            SELECT * FROM user_book_lists WHERE id = %s
        """, (list_id,))

        if list_info['user_id'] != owner_id:
            raise PermissionError("Only owner can invite collaborators")

        # 2. åˆ›å»ºé‚€è¯·
        await mysql.execute("""
            INSERT INTO user_book_list_collaborators
            (list_id, user_id, role, invited_by, invited_at)
            VALUES (%s, %s, %s, %s, NOW())
        """, (list_id, invitee_user_id, role, owner_id))

        # 3. æ¨é€é€šçŸ¥
        await notification_service.send_push(
            invitee_user_id,
            title="ä¹¦å•åä½œé‚€è¯·",
            body=f"é‚€è¯·ä½ ä¸€èµ·ç»´æŠ¤ä¹¦å•ã€Š{list_info['list_name']}ã€‹"
        )

    async def accept_invitation(self, user_id: int, list_id: int):
        """æ¥å—åä½œé‚€è¯·"""
        await mysql.execute("""
            UPDATE user_book_list_collaborators
            SET accepted_at = NOW()
            WHERE list_id = %s AND user_id = %s
        """, (list_id, user_id))

    async def add_book_to_list(self, list_id: int, user_id: int,
                              book_id: int, recommendation_reason: str = None):
        """æ·»åŠ å›¾ä¹¦åˆ°ä¹¦å•ï¼ˆåä½œè€…å¯æ“ä½œï¼‰"""
        # 1. æ£€æŸ¥æƒé™
        has_permission = await self.check_permission(
            list_id, user_id, 'add_book'
        )

        if not has_permission:
            raise PermissionError("No permission to add books")

        # 2. æ·»åŠ å›¾ä¹¦
        await mysql.execute("""
            INSERT INTO user_book_list_items
            (list_id, book_id, recommendation_reason, added_by, created_at)
            VALUES (%s, %s, %s, %s, NOW())
        """, (list_id, book_id, recommendation_reason, user_id))

        # 3. æ›´æ–°ä¹¦å•çš„å›¾ä¹¦æ•°é‡
        await mysql.execute("""
            UPDATE user_book_lists
            SET books_count = books_count + 1
            WHERE id = %s
        """, (list_id,))

        # 4. é€šçŸ¥å…¶ä»–åä½œè€…
        await self.notify_collaborators(
            list_id, user_id,
            f"æ·»åŠ äº†æ–°ä¹¦åˆ°ä¹¦å•"
        )

    async def check_permission(self, list_id: int, user_id: int,
                              action: str) -> bool:
        """æ£€æŸ¥æƒé™"""
        # 1. æ£€æŸ¥æ˜¯å¦ä¸ºä¹¦å•æ‰€æœ‰è€…
        list_info = await mysql.fetchone("""
            SELECT user_id FROM user_book_lists WHERE id = %s
        """, (list_id,))

        if list_info['user_id'] == user_id:
            return True  # æ‰€æœ‰è€…æ‹¥æœ‰æ‰€æœ‰æƒé™

        # 2. æ£€æŸ¥åä½œè€…æƒé™
        collaborator = await mysql.fetchone("""
            SELECT role, permissions FROM user_book_list_collaborators
            WHERE list_id = %s AND user_id = %s
            AND accepted_at IS NOT NULL
        """, (list_id, user_id))

        if not collaborator:
            return False

        # 3. æ ¹æ®è§’è‰²æ£€æŸ¥æƒé™
        if collaborator['role'] == 'editor':
            return action in ['add_book', 'remove_book', 'reorder']
        elif collaborator['role'] == 'contributor':
            return action in ['add_book']

        return False
```

---

## 4. é€šçŸ¥ä¸æé†’ä¼˜åŒ–

### 4.1 æ™ºèƒ½é˜…è¯»æé†’

```python
class SmartReadingReminder:
    """æ™ºèƒ½é˜…è¯»æé†’æœåŠ¡"""

    async def schedule_reminders(self, user_id: int):
        """ä¸ºç”¨æˆ·å®‰æ’é˜…è¯»æé†’"""
        # 1. åˆ†æç”¨æˆ·çš„é˜…è¯»ä¹ æƒ¯
        habits = await self.analyze_reading_habits(user_id)

        # 2. æ ¹æ®ä¹ æƒ¯å®‰æ’æé†’æ—¶é—´
        if habits['preferred_time'] == 'morning':
            reminder_time = '08:30'
        elif habits['preferred_time'] == 'afternoon':
            reminder_time = '14:00'
        elif habits['preferred_time'] == 'evening':
            reminder_time = '20:00'
        else:
            reminder_time = '19:00'  # é»˜è®¤æ™šä¸Š7ç‚¹

        # 3. åˆ›å»ºå®šæ—¶æé†’
        await self.create_scheduled_notification(
            user_id,
            reminder_time,
            title="è¯¥è¯»ä¹¦äº†ğŸ“š",
            body=self.generate_reminder_message(habits)
        )

    async def analyze_reading_habits(self, user_id: int) -> dict:
        """åˆ†æç”¨æˆ·é˜…è¯»ä¹ æƒ¯"""
        # æŸ¥è¯¢æœ€è¿‘30å¤©çš„é˜…è¯»è®°å½•
        reading_logs = await mysql.fetchall("""
            SELECT HOUR(last_reading_at) as hour,
                   COUNT(*) as count
            FROM user_reading_records
            WHERE user_id = %s
            AND last_reading_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
            GROUP BY HOUR(last_reading_at)
            ORDER BY count DESC
        """, (user_id,))

        if not reading_logs:
            return {'preferred_time': 'evening', 'avg_duration': 30}

        # æ‰¾åˆ°æœ€å¸¸é˜…è¯»çš„æ—¶é—´æ®µ
        most_frequent_hour = reading_logs[0]['hour']

        if 6 <= most_frequent_hour < 12:
            preferred_time = 'morning'
        elif 12 <= most_frequent_hour < 18:
            preferred_time = 'afternoon'
        else:
            preferred_time = 'evening'

        # è®¡ç®—å¹³å‡é˜…è¯»æ—¶é•¿
        avg_duration = await mysql.fetchone("""
            SELECT AVG(reading_duration) as avg
            FROM user_reading_records
            WHERE user_id = %s
            AND last_reading_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
        """, (user_id,))

        return {
            'preferred_time': preferred_time,
            'avg_duration': int(avg_duration['avg'] or 30)
        }

    def generate_reminder_message(self, habits: dict) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–æé†’æ¶ˆæ¯"""
        duration = habits['avg_duration']

        messages = [
            f"æ¯å¤©{duration}åˆ†é’Ÿé˜…è¯»ï¼Œè®©çŸ¥è¯†æ²‰æ·€",
            f"ä»Šå¤©çš„{duration}åˆ†é’Ÿé˜…è¯»è®¡åˆ’ï¼Œå¼€å§‹äº†å—ï¼Ÿ",
            f"é˜…è¯»æ˜¯æœ€å¥½çš„æŠ•èµ„ï¼Œæ¥è¯»{duration}åˆ†é’Ÿå§",
            "ä¹¦ç±æ˜¯äººç±»è¿›æ­¥çš„é˜¶æ¢¯ï¼Œä¸€èµ·çˆ¬ä¸€å±‚å§",
            "ä½ çš„ä¹¦æ¶ä¸Šè¿˜æœ‰æœªå®Œæˆçš„æ•…äº‹åœ¨ç­‰ä½ "
        ]

        import random
        return random.choice(messages)
```

---

## 5. æ€»ç»“ä¸ä¼˜å…ˆçº§

### 5.1 ç”¨æˆ·ä½“éªŒä¼˜åŒ–å®æ–½è·¯çº¿å›¾

| ä¼˜åŒ–é¡¹ | ç”¨æˆ·ä»·å€¼ | ä¼˜å…ˆçº§ | å®æ–½å¤æ‚åº¦ | é¢„æœŸè€—æ—¶ |
|-------|---------|-------|-----------|---------|
| è·¨è®¾å¤‡å®æ—¶åŒæ­¥ | â­â­â­â­â­ | ğŸ”´ P0 | é«˜ | 4-5å‘¨ |
| ç¦»çº¿é˜…è¯»æ”¯æŒ | â­â­â­â­â­ | ğŸ”´ P0 | é«˜ | 3-4å‘¨ |
| æ–­ç‚¹ç»­ä¼ ä¸‹è½½ | â­â­â­â­ | ğŸŸ¡ P1 | ä¸­ | 2å‘¨ |
| æ™ºèƒ½é¢„ä¸‹è½½ | â­â­â­ | ğŸŸ¢ P2 | ä¸­ | 2å‘¨ |
| ç¬”è®°ç¤¾åŒºFeed | â­â­â­â­ | ğŸŸ¡ P1 | ä¸­ | 3å‘¨ |
| åä½œä¹¦å• | â­â­â­ | ğŸŸ¢ P2 | ä¸­ | 2å‘¨ |
| æ™ºèƒ½é˜…è¯»æé†’ | â­â­â­ | ğŸŸ¢ P2 | ä½ | 1å‘¨ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-10-14
**ä¸‹ä¸€æ­¥**: æŸ¥çœ‹ã€Š04-ä¸šåŠ¡å¢é•¿ç­–ç•¥æ–‡æ¡£ã€‹
